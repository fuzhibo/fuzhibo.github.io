<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.0.0">Jekyll</generator><link href="https://fuzhibo.site/feed.xml" rel="self" type="application/atom+xml" /><link href="https://fuzhibo.site/" rel="alternate" type="text/html" /><updated>2019-12-19T11:26:33+08:00</updated><id>https://fuzhibo.site/feed.xml</id><title type="html">A tossing programmer</title><subtitle>This blog documented my learing trajectory.</subtitle><entry><title type="html">折腾 ruby 的一些日常记录</title><link href="https://fuzhibo.site/ruby/2019/12/18/record-ruby-tossing-history.html" rel="alternate" type="text/html" title="折腾 ruby 的一些日常记录" /><published>2019-12-18T14:18:29+08:00</published><updated>2019-12-18T14:18:29+08:00</updated><id>https://fuzhibo.site/ruby/2019/12/18/record-ruby-tossing-history</id><content type="html" xml:base="https://fuzhibo.site/ruby/2019/12/18/record-ruby-tossing-history.html">&lt;h3 id=&quot;2018-12-18&quot;&gt;2018-12-18&lt;/h3&gt;
&lt;p&gt;  突然发现 &lt;code class=&quot;highlighter-rouge&quot;&gt;gem update --system&lt;/code&gt; 没有作用了，系统环境是 &lt;code class=&quot;highlighter-rouge&quot;&gt;Ubuntu 18.04.3 LTS&lt;/code&gt;。 一开始是因为遇到了 &lt;a href=&quot;https://bundler.io/blog/2019/05/14/solutions-for-cant-find-gem-bundler-with-executable-bundle.html&quot;&gt;Cant find gem bundler (&amp;gt;= 0.a) with executable bundle&lt;/a&gt; 的问题。查看了下当前环境中的 gem 版本，是 &lt;code class=&quot;highlighter-rouge&quot;&gt;2.7.7&lt;/code&gt;。很显然，解决问题的关键始终是升级。不过运行了 &lt;code class=&quot;highlighter-rouge&quot;&gt;gem update --system&lt;/code&gt; 后，系统却告知已经是最新版本。&lt;/p&gt;
&lt;div class=&quot;language-console highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;gp&quot;&gt;root&amp;gt;&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;gem update &lt;span class=&quot;nt&quot;&gt;--system&lt;/span&gt;
&lt;span class=&quot;go&quot;&gt;Latest version already installed. Done.
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;  既然已经不能使用默认的方式升级，只能指定版本了 &lt;code class=&quot;highlighter-rouge&quot;&gt;gem update --system '3.0.6'&lt;/code&gt;，经过一系列安装后，升级成功。&lt;/p&gt;

&lt;hr /&gt;</content><author><name></name></author><summary type="html">2018-12-18   突然发现 gem update --system 没有作用了，系统环境是 Ubuntu 18.04.3 LTS。 一开始是因为遇到了 Cant find gem bundler (&amp;gt;= 0.a) with executable bundle 的问题。查看了下当前环境中的 gem 版本，是 2.7.7。很显然，解决问题的关键始终是升级。不过运行了 gem update --system 后，系统却告知已经是最新版本。 root&amp;gt; gem update --system Latest version already installed. Done.   既然已经不能使用默认的方式升级，只能指定版本了 gem update --system '3.0.6'，经过一系列安装后，升级成功。</summary></entry><entry><title type="html">实现一个 python 版本的 Crond Service</title><link href="https://fuzhibo.site/python,crond/2019/12/18/implement-python-crond-service.html" rel="alternate" type="text/html" title="实现一个 python 版本的 Crond Service" /><published>2019-12-18T12:18:29+08:00</published><updated>2019-12-18T12:18:29+08:00</updated><id>https://fuzhibo.site/python,crond/2019/12/18/implement-python-crond-service</id><content type="html" xml:base="https://fuzhibo.site/python,crond/2019/12/18/implement-python-crond-service.html">&amp;emsp;&amp;emsp;在微服务的实践中，所有的应用都被打包成了容器。但是总会遇到一些作业定时调度的需求，在不知道有 `APScheduler` 的情况下通常的办法都会想到用 Linux 系统中自带的 Crond Service 来完成相应的作业调度功能。那么如果要将这部分的实现迁移到容器中来，大多数情况下会选择同时集成 Crond Service 到容器。这就破坏了`一个进程一个容器`的容器设计思想，并且在实际的运行过程中 Crond Service 的运行也不是足够的稳定。默认情况下 Crond Service 启动后，会自动在 `/var/run/` 中创建一个 `crond.pid` 文件。如果为镜像新增了什么配置并且使用 `docker commit` 重新打包了之后，这个 `crond.pid` 文件也会被打包并会干扰到下次的容器启动或者 `docker exec` 的操作。  
&amp;emsp;  
&amp;emsp;&amp;emsp;在知道了 `APScheduler` 后，一个办法是通过重构将原有的调度全部放到代码中，但是这种重构带来的问题是未来每次新增一个作业调度都要增加代码。无疑是大大的增加了服务开发的时间。另外一个办法是考虑实现一个 python 版本的 Crond Service 服务。  
&amp;emsp;  
&amp;emsp;&amp;emsp;因为存在 `python-crontab` 这样的库，使用 python 管理 `crontab` 文件的复杂度被大大的降低，而同时结合 `APScheduler` 就可以实现一个 python 版本的 Crond Service 服务。  
```python
import os
import datetime
import json
import time
import requests
import traceback
import hashlib
from watchdog.observers import Observer
from crontab import CronTab
from watchdog.events import FileSystemEventHandler
from threading import Thread, Event
import queue as Queue
from apscheduler.schedulers.background import BackgroundScheduler
from cmop.common.log import info, warn, debug, error
from cmop.common.rabbitmq_interface import RabbitmqService
from cmop.common.utils import RedisClient, run_local_command, byteify

REDIS_HOST = &quot;redis-master&quot;
REDIS_PORT = 6379
SYSTEM_CRONTAB = &quot;/etc/crontab&quot;
CROND_SERVICE_PREFIX = &quot;crond-service-cronjob-cache&quot;

MSGQUEUE = Queue.Queue()
CROND_RESTART_EVENT = Event()


class SchedulerManagement(object):

    scheduler_dict = {}
    start_flag_dict = {}

    def __init__(self, key_prefix):
        self._scheduler_key_prefix = key_prefix
        if not self.scheduler:
            info(f&quot;Init scheduler: {self._scheduler_key_prefix}&quot;)
            self.start_flag = False
            self.scheduler = BackgroundScheduler()
            self.scheduler.configure(
                job_defaults={
                    &quot;coalesce&quot;: True,
                    &quot;max_instances&quot;: 3000,
                    &quot;misfire_grace_time&quot;: 60,
                }
            )
            self.scheduler.add_jobstore(
                &quot;redis&quot;,
                jobs_key=&quot;{0}.jobs&quot;.format(key_prefix),
                run_times_key=&quot;{0}.run_times&quot;.format(key_prefix),
                host=&quot;redis-master&quot;,
                port=6379,
            )
        else:
            info(f&quot;Scheduler: {self._scheduler_key_prefix} has already started, ignore initialize...&quot;)

    @property
    def scheduler(self):
        if self._scheduler_key_prefix not in SchedulerManagement.scheduler_dict:
            return None
        else:
            return SchedulerManagement.scheduler_dict[self._scheduler_key_prefix]

    @scheduler.setter
    def scheduler(self, value):
        if not value:
            # delete related instance
            info(f&quot;Scheduler {self._scheduler_key_prefix} will be destroy...&quot;)
            del SchedulerManagement.scheduler_dict[self._scheduler_key_prefix]
        SchedulerManagement.scheduler_dict[self._scheduler_key_prefix] = value

    @property
    def start_flag(self):
        if self._scheduler_key_prefix not in SchedulerManagement.start_flag_dict:
            SchedulerManagement.start_flag_dict[self._scheduler_key_prefix] = False

        return SchedulerManagement.start_flag_dict[self._scheduler_key_prefix]

    @start_flag.setter
    def start_flag(self, value):
        SchedulerManagement.start_flag_dict[self._scheduler_key_prefix] = value

    def run(self):
        if not self.start_flag:
            self.scheduler.start()
            self.start_flag = True
        info(&quot;Start scheduler [%s]...&quot; % (self.start_flag))

    def shutdown(self):
        if self.start_flag:
            self.scheduler.shutdown()
            self.start_flag = False
            self.scheduler = None
        info(&quot;Stop scheduler...&quot;)

    def _send_schedule_notify(self, exchange, routing_key, record):
        info(&quot;Begin to send scheduled notify...&quot;)
        try:
            rs = RabbitmqService()
            rs.publish(exchange, routing_key, message=record)
        except Exception as ex:
            error(traceback.format_exc())
            error(&quot;Failed to send data %r due to %r&quot; % (record, ex))

    def add_common_notify_callback(
        self, m=&quot;*&quot;, h=&quot;*&quot;, dom=&quot;*&quot;, mon=&quot;*&quot;, dow=&quot;*&quot;, jobid=None, cb=None, cb_args=None
    ):
        job = self.scheduler.get_job(jobid)
        if job:
            info(f&quot;The job {jobid} has already exists, ignore...&quot;)
        else:
            info(&quot;Add notify callback...&quot;)
            self.scheduler.add_job(
                cb,
                args=cb_args,
                trigger=&quot;cron&quot;,
                minute=m,
                hour=h,
                day=dom,
                month=mon,
                day_of_week=dow,
                start_date=datetime.datetime.now(),
                id=jobid,
            )
            self.scheduler.resume()

    def add_common_notify_callback_once(
        self, run_date, jobid=None, cb=None, cb_args=None
    ):
        info(&quot;Add once notify callback...&quot;)
        self.scheduler.add_job(
            cb, args=cb_args, trigger=&quot;date&quot;, run_date=run_date, id=jobid
        )
        self.scheduler.resume()

    def remove_all_jobs(self):
        self.scheduler.remove_all_jobs()

    def remove_job(self, jobid=None):
        if jobid:
            job = self.scheduler.get_job(jobid)
            if job:
                self.scheduler.remove_job(jobid)
        else:
            self.scheduler.remove_all_jobs()

    def add_schedule(
        self, m=&quot;*&quot;, h=&quot;*&quot;, dom=&quot;*&quot;, mon=&quot;*&quot;, dow=&quot;*&quot;, jobid=None, cb=None, cb_args=()
    ):
        info(&quot;Add new scheduled job...&quot;)
        cb = cb or self._send_schedule_notify
        if jobid:
            redis_clt = RedisClient(REDIS_HOST, REDIS_PORT, decode_responses=True)
            body = redis_clt.client.hget(self._scheduler_key_prefix, jobid)
            if body:
                cb_args += (body,)
        self.add_common_notify_callback(
            m=m, h=h, dom=dom, mon=mon, dow=dow, jobid=jobid, cb=cb, cb_args=cb_args
        )

    def add_schedule_once(self, run_date=None, jobid=None, cb=None, cb_args=()):
        info(&quot;Add new once scheduled job...&quot;)
        cb = cb or self._send_schedule_notify
        if jobid:
            redis_clt = RedisClient(REDIS_HOST, REDIS_PORT, decode_responses=True)
            body = redis_clt.client.hget(self._scheduler_key_prefix, jobid)
            if body:
                cb_args += (body,)
        if run_date:
            self.add_common_notify_callback_once(
                run_date=run_date, jobid=jobid, cb=cb, cb_args=cb_args
            )
        else:
            info(&quot;Failed to get schedule run date, ignore cron config...&quot;)


class CronTabEventHandler(FileSystemEventHandler):
    &quot;&quot;&quot;Logs all the events captured.&quot;&quot;&quot;

    def on_moved(self, event):
        super(CronTabEventHandler, self).on_moved(event)

        what = &quot;directory&quot; if event.is_directory else &quot;file&quot;
        debug(f&quot;Moved {what}: from {event.src_path} to {event.dest_path}&quot;)

    def on_created(self, event):
        super(CronTabEventHandler, self).on_created(event)

        what = &quot;directory&quot; if event.is_directory else &quot;file&quot;
        debug(f&quot;Created {what}: {event.src_path}&quot;)

    def on_deleted(self, event):
        super(CronTabEventHandler, self).on_deleted(event)

        what = &quot;directory&quot; if event.is_directory else &quot;file&quot;
        debug(f&quot;Deleted {what}: {event.src_path}&quot;)

    def on_modified(self, event):
        super(CronTabEventHandler, self).on_modified(event)
        redis_clt = RedisClient(REDIS_HOST, REDIS_PORT, decode_responses=True)
        if not event.is_directory and event.src_path == SYSTEM_CRONTAB:
            debug(f&quot;Modified file: {event.src_path}&quot;)
            # read the crontab file and set it to apscheduler
            # clean redis
            redis_clt.client.delete(CROND_SERVICE_PREFIX)
            system_cron = CronTab(tabfile=SYSTEM_CRONTAB, user=False)
            cron_jobs = []
            for job in system_cron:
                job_mark = f&quot;{str(job.minute)},{str(job.hour)},{str(job.dom)},{str(job.month)},{str(job.dow)},{job.user},{job.command}&quot;
                jobid = f&quot;crondServiceTask-{hashlib.md5(job_mark.encode('utf-8')).hexdigest()[8:-8]}&quot;
                MSGQUEUE.put(
                    (
                        str(job.minute),
                        str(job.hour),
                        str(job.dom),
                        str(job.month),
                        str(job.dow),
                        jobid,
                        job.command,
                    )
                )
                cron_jobs.append(
                    [
                        str(job.minute),
                        str(job.hour),
                        str(job.dom),
                        str(job.month),
                        str(job.dow),
                        job.user,
                        job.command,
                    ]
                )
            else:
                # record in redis
                redis_clt.client.set(CROND_SERVICE_PREFIX, json.dumps(cron_jobs))
                # clean current jobs and restart crond service
                CROND_RESTART_EVENT.set()


class CrondService(Thread):
    &quot;&quot;&quot;Start a thread run like crond service&quot;&quot;&quot;

    def __init__(self, name, **kwargs):

        super(CrondService, self).__init__(name=name)

    def _recovery_system_crontab(self):
        # check the file has already existed
        if not os.path.exists(SYSTEM_CRONTAB):
            info(f&quot;There is no related file {SYSTEM_CRONTAB}, will create one...&quot;)
            fp = open(SYSTEM_CRONTAB, &quot;x&quot;)
            fp.close()
        # recovery from redis and write to /etc/crontab
        info(&quot;Recovery crond setting from redis...&quot;)
        redis_clt = RedisClient(REDIS_HOST, REDIS_PORT, decode_responses=True)
        body = redis_clt.client.get(CROND_SERVICE_PREFIX)
        crond_info = json.loads(body, object_hook=byteify) if body else None
        if crond_info:
            system_cron = CronTab(tabfile=SYSTEM_CRONTAB, user=False)
            for cron in crond_info:
                m, h, dom, mon, dow, user, cmd = cron
                job_mark = (
                    f&quot;{str(m)},{str(h)},{str(dom)},{str(mon)},{str(dow)},{user},{cmd}&quot;
                )
                jobid = f&quot;crondServiceTask-{hashlib.md5(job_mark.encode('utf-8')).hexdigest()[8:-8]}&quot;
                newjob = system_cron.new(
                    command=cmd, comment=f&quot;crond service {jobid}&quot;, user=user
                )
                newjob.setall(f&quot;{str(m)} {str(h)} {str(dom)} {str(mon)} {str(dow)}&quot;)
                MSGQUEUE.put(
                    (
                        str(m),
                        str(h),
                        str(dom),
                        str(mon),
                        str(dow),
                        jobid,
                        cmd,
                    )
                )
            else:
                system_cron.write()
                info(&quot;Recovery crond setting completed.&quot;)
        else:
            info(&quot;There is no related cron job record in cache, ignore recovery...&quot;)

    def run(self):
        info(&quot;Begin to start crond service monitor...&quot;)
        crond_tid = None
        # recovery the cron job
        self._recovery_system_crontab()
        # create a new thread to run crond service
        while True:
            if not crond_tid:
                crond_tid = Thread(target=self._crond_service_run)
                crond_tid.start()
                # try some counts to wait the thread alive
                for _ in range(3):
                    if crond_tid.isAlive():
                        break
                    else:
                        warn(&quot;crond service thread is not ready, waitting..&quot;)
                        time.sleep(2)
                else:
                    warn(&quot;crond service can not be ready.&quot;)
                    break
                info(&quot;Crond service started...&quot;)
            else:
                # monitor the event and restart the thread
                CROND_RESTART_EVENT.wait()
                # restart the crond service
                # waith the thread stop
                info(&quot;Waitting for Crond service stop...&quot;)
                crond_tid.join()
                crond_tid = None
                info(&quot;Crond service stopped...&quot;)
                CROND_RESTART_EVENT.clear()
        else:
            info(&quot;Crond service has quit...&quot;)

    def _crond_service_run(self):

        info(&quot;Begin to start Crond Service...&quot;)
        path = &quot;/etc&quot;
        event_handler = CronTabEventHandler()
        observer = Observer()
        info(&quot;Begin to watch /etc/crontab file...&quot;)
        observer.schedule(event_handler, path, recursive=True)
        observer.start()
        key_prefix = &quot;crond_service_schedule&quot;
        sch_manage = SchedulerManagement(key_prefix=key_prefix)
        sch_manage.run()
        # remove all jobs
        sch_manage.remove_job()
        while True:
            msg_consumed = False
            try:
                # get the crontab setting and set to
                # apscheduler
                if not MSGQUEUE.empty():
                    m, h, dom, mon, dow, jobid, cmd = MSGQUEUE.get(
                        block=False, timeout=3
                    )
                    msg_consumed = True
                    sch_manage.add_schedule(
                        m, h, dom, mon, dow, jobid, run_local_command, (cmd,)
                    )
                else:
                    # check the Event and decide if quit
                    if CROND_RESTART_EVENT.wait(timeout=1):
                        info(&quot;Thread recive the quit event, will quite...&quot;)
                        break
            except Exception as ex:
                error(traceback.format_exc())
                error(f&quot;Failed to run crond service scheduler manager due to {str(ex)}&quot;)
                break
            finally:
                if msg_consumed:
                    MSGQUEUE.task_done()

        observer.stop()
        observer.join()
        sch_manage.shutdown()

if __name__ == '__main__':
    # start crond service
    crond = CrondService(&quot;crond-service&quot;)
    crond.start()
```
&amp;emsp;&amp;emsp;流程图如下：

{% mermaid %}
graph TD;
    A--&gt;B;
    A--&gt;C;
    B--&gt;D;
    C--&gt;D;
{% endmermaid %}</content><author><name></name></author><summary type="html">  在微服务的实践中，所有的应用都被打包成了容器。但是总会遇到一些作业定时调度的需求，在不知道有 APScheduler 的情况下通常的办法都会想到用 Linux 系统中自带的 Crond Service 来完成相应的作业调度功能。那么如果要将这部分的实现迁移到容器中来，大多数情况下会选择同时集成 Crond Service 到容器。这就破坏了一个进程一个容器的容器设计思想，并且在实际的运行过程中 Crond Service 的运行也不是足够的稳定。默认情况下 Crond Service 启动后，会自动在 /var/run/ 中创建一个 crond.pid 文件。如果为镜像新增了什么配置并且使用 docker commit 重新打包了之后，这个 crond.pid 文件也会被打包并会干扰到下次的容器启动或者 docker exec 的操作。     在知道了 APScheduler 后，一个办法是通过重构将原有的调度全部放到代码中，但是这种重构带来的问题是未来每次新增一个作业调度都要增加代码。无疑是大大的增加了服务开发的时间。另外一个办法是考虑实现一个 python 版本的 Crond Service 服务。     因为存在 python-crontab 这样的库，使用 python 管理 crontab 文件的复杂度被大大的降低，而同时结合 APScheduler 就可以实现一个 python 版本的 Crond Service 服务。 ```python import os import datetime import json import time import requests import traceback import hashlib from watchdog.observers import Observer from crontab import CronTab from watchdog.events import FileSystemEventHandler from threading import Thread, Event import queue as Queue from apscheduler.schedulers.background import BackgroundScheduler from cmop.common.log import info, warn, debug, error from cmop.common.rabbitmq_interface import RabbitmqService from cmop.common.utils import RedisClient, run_local_command, byteify</summary></entry><entry><title type="html">使用 colorama 让 python 日志输出带有各种颜色标识</title><link href="https://fuzhibo.site/python,colorama/2019/12/15/use-colorama-in-python.html" rel="alternate" type="text/html" title="使用 colorama 让 python 日志输出带有各种颜色标识" /><published>2019-12-15T12:18:29+08:00</published><updated>2019-12-15T12:18:29+08:00</updated><id>https://fuzhibo.site/python,colorama/2019/12/15/use-colorama-in-python</id><content type="html" xml:base="https://fuzhibo.site/python,colorama/2019/12/15/use-colorama-in-python.html">&amp;emsp;&amp;emsp;在日常的程序调试工作中，最常用的手段就是看日志。但是大量的日志输出总是让人头昏眼花，于是就有了给日志标识颜色来区分不同输出的需求。  
&amp;emsp;  
&amp;emsp;&amp;emsp;在 python 中，可以使用 colorama 来完成对输出日志的颜色标注。从原来上来说本质是集成了控制台的颜色控制符，使其在 python 环境中更加的易用。不过日常使用中，多是和 logging 模块集成来方便日志输出的颜色标识。  
&amp;emsp;  
&amp;emsp;&amp;emsp;在 colorama 中，主要有如下的三个模块：
|模块|参数|
| :-----: | :----- |
| Fore | BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET |
| Back | BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET |
| Style | DIM, NORMAL, BRIGHT, RESET_ALL |
&amp;emsp;&amp;emsp;其中，Fore 主要是用于设置字体本身的颜色，Back 用于设置字符的背景颜色，Style 用于设置字体本身的风格。需要注意的是，在指定的范围内设置颜色一定要在结尾加上 RESET 的操作。
```python
import re
import sys
import logging
from logging import StreamHandler
from colorama import init as colorama_init
from colorama import Fore, Back, Style


COLORS = {
    &quot;WARNING&quot;: Fore.YELLOW,
    &quot;INFO&quot;: Fore.WHITE,
    &quot;DEBUG&quot;: Fore.BLUE,
    &quot;CRITICAL&quot;: Fore.RED + Style.BRIGHT,
    &quot;ERROR&quot;: Fore.RED,
}

COLORS_END = {
    &quot;WARNING&quot;: Fore.RESET,
    &quot;INFO&quot;: Fore.RESET,
    &quot;DEBUG&quot;: Fore.RESET,
    &quot;CRITICAL&quot;: Fore.RESET + Style.RESET_ALL,
    &quot;ERROR&quot;: Fore.RESET,
}


class ColoredFormatter(logging.Formatter):
    def __init__(self, fmt=None, datefmt=None, style=&quot;%&quot;, use_color=True):
        super(ColoredFormatter, self).__init__(fmt, datefmt)
        self.use_color = use_color
        self.p = re.compile(r&quot;([\&quot;|\s])([\w]+-[\w|\d]+)([\&quot;|\s])&quot;)
        self.http_p = re.compile(r&quot;http[s]*://[^ |$]+&quot;)

    def format(self, record):
        levelname = record.levelname
        if self.use_color and levelname in COLORS:
            record.filename = (
                Fore.CYAN
                + Style.BRIGHT
                + record.filename
                + Fore.RESET
                + Style.RESET_ALL
            )
            record.levelname = COLORS[levelname] + levelname + COLORS_END[levelname]
            record.msg = self.p.sub(
                lambda e: e.group(1)
                + COLORS_END[levelname]
                + Fore.GREEN
                + Style.BRIGHT
                + e.group(2)
                + Fore.RESET
                + Style.RESET_ALL
                + COLORS[levelname]
                + e.group(3),
                record.msg,
            )
            if &quot;http&quot; in record.msg:
                record.msg = self.http_p.sub(
                    lambda e: COLORS_END[levelname]
                    + Fore.CYAN
                    + Style.BRIGHT
                    + e.group(0)
                    + Fore.RESET
                    + Style.RESET_ALL
                    + COLORS[levelname],
                    record.msg,
                )
            record.msg = COLORS[levelname] + record.msg + COLORS_END[levelname]
        return logging.Formatter.format(self, record)

def debug(msg):
    logger.debug(msg)

if __name__ == &quot;__main__&quot;:
    colorama_init()
    handler = StreamHandler()
    handler.setLevel(logging.DEBUG)
    fmt_str = &quot;%(asctime)s - [pid:%(process)d][tid:%(thread)d](%(filename)s:%(lineno)d) - %(levelname)s: %(message)s&quot;
    formatter = ColoredFormatter(fmt_str)
    handler.setFormatter(formatter)
    logger = logging.getLogger(__name__)
    logger.setLevel(logging.DEBUG)
    logger.addHandler(handler)
    debug(&quot;debug&quot;)
    logger.info(&quot;Check if instance-iXt3Lce1 can be connected...&quot;)
    logger.warn(
        &quot;warn  http://www.bing.com&quot;
    )
    logger.error(
        '{&quot;taskCode&quot;: &quot;task-a912a3ef70034366a7f6dd77a9c9d4e4&quot;, &quot;instanceId&quot;: &quot;instance-i0dTif33&quot;}'
    )
    logger.critical(&quot;critical&quot;)
```
&amp;emsp;&amp;emsp;上面这段代码，基本就是通过定制 logging 的 formatter 来花式的实现各种日志的颜色标注。</content><author><name></name></author><summary type="html">  在日常的程序调试工作中，最常用的手段就是看日志。但是大量的日志输出总是让人头昏眼花，于是就有了给日志标识颜色来区分不同输出的需求。     在 python 中，可以使用 colorama 来完成对输出日志的颜色标注。从原来上来说本质是集成了控制台的颜色控制符，使其在 python 环境中更加的易用。不过日常使用中，多是和 logging 模块集成来方便日志输出的颜色标识。     在 colorama 中，主要有如下的三个模块： |模块|参数| | :—–: | :—– | | Fore | BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET | | Back | BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET | | Style | DIM, NORMAL, BRIGHT, RESET_ALL |   其中，Fore 主要是用于设置字体本身的颜色，Back 用于设置字符的背景颜色，Style 用于设置字体本身的风格。需要注意的是，在指定的范围内设置颜色一定要在结尾加上 RESET 的操作。 ```python import re import sys import logging from logging import StreamHandler from colorama import init as colorama_init from colorama import Fore, Back, Style</summary></entry><entry><title type="html">对于 Python 3 中的 threading 模块阅读笔记</title><link href="https://fuzhibo.site/python,colorama/2019/12/15/inspect-python3-threading-module.html" rel="alternate" type="text/html" title="对于 Python 3 中的 threading 模块阅读笔记" /><published>2019-12-15T12:18:29+08:00</published><updated>2019-12-15T12:18:29+08:00</updated><id>https://fuzhibo.site/python,colorama/2019/12/15/inspect-python3-threading-module</id><content type="html" xml:base="https://fuzhibo.site/python,colorama/2019/12/15/inspect-python3-threading-module.html">&amp;emsp;&amp;emsp;这个想法起初只是为了找到 python 3 下的 **threading.Thread** 中类似于线程关闭的方法，可惜似乎没有直接的实现。在 python 2 下 Thread 实例的退出可以调用 **Thread._Thread__stop()** 方法来完成，但是这个内置方法在 python 3 下已经没有，通过代码跟踪发现 `threading.py` 并不是实现 python 线程的基础文件，真正的启动操作应该是调用 cpython 暴露出来的 **start_new_thread** 方法来完成启动，在启动的同时传入了 **self._bootstrap()** 做一些初始化操作：  
```python
def start(self):
	&quot;&quot;&quot;Start the thread's activity.

	It must be called at most once per thread object. It arranges for the
	object's run() method to be invoked in a separate thread of control.

	This method will raise a RuntimeError if called more than once on the
	same thread object.

	&quot;&quot;&quot;
	if not self._initialized:
	    raise RuntimeError(&quot;thread.__init__() not called&quot;)

	if self._started.is_set():
	    raise RuntimeError(&quot;threads can only be started once&quot;)
	with _active_limbo_lock:
	    _limbo[self] = self
	try:
	    _start_new_thread(self._bootstrap, ())
	except Exception:
	    with _active_limbo_lock:
		del _limbo[self]
	    raise
	self._started.wait()
```
&amp;emsp;&amp;emsp;**_start_new_thread** 的真正实现应该在 cpython 源码下的 `Modules/_threadmodule.c` 中：
```c
static PyObject *
thread_PyThread_start_new_thread(PyObject *self, PyObject *fargs)
{
    PyObject *func, *args, *keyw = NULL;
    struct bootstate *boot;
    unsigned long ident;

    if (!PyArg_UnpackTuple(fargs, &quot;start_new_thread&quot;, 2, 3,
                           &amp;func, &amp;args, &amp;keyw))
        return NULL;
    if (!PyCallable_Check(func)) {
        PyErr_SetString(PyExc_TypeError,
                        &quot;first arg must be callable&quot;);
        return NULL;
    }
    if (!PyTuple_Check(args)) {
        PyErr_SetString(PyExc_TypeError,
                        &quot;2nd arg must be a tuple&quot;);
        return NULL;
    }
    if (keyw != NULL &amp;&amp; !PyDict_Check(keyw)) {
        PyErr_SetString(PyExc_TypeError,
                        &quot;optional 3rd arg must be a dictionary&quot;);
        return NULL;
    }
    boot = PyMem_NEW(struct bootstate, 1);
    if (boot == NULL)
        return PyErr_NoMemory();
    boot-&gt;interp = _PyInterpreterState_Get();
    boot-&gt;func = func;
    boot-&gt;args = args;
    boot-&gt;keyw = keyw;
    boot-&gt;tstate = _PyThreadState_Prealloc(boot-&gt;interp);
    if (boot-&gt;tstate == NULL) {
        PyMem_DEL(boot);
        return PyErr_NoMemory();
    }
    Py_INCREF(func);
    Py_INCREF(args);
    Py_XINCREF(keyw);
    PyEval_InitThreads(); /* Start the interpreter's thread-awareness */
    ident = PyThread_start_new_thread(t_bootstrap, (void*) boot);
    if (ident == PYTHREAD_INVALID_THREAD_ID) {
        PyErr_SetString(ThreadError, &quot;can't start new thread&quot;);
        Py_DECREF(func);
        Py_DECREF(args);
        Py_XDECREF(keyw);
        PyThreadState_Clear(boot-&gt;tstate);
        PyMem_DEL(boot);
        return NULL;
    }
    return PyLong_FromUnsignedLong(ident);
}
```
&amp;emsp;&amp;emsp;这里可以看到，这个方法使用 c 语言实现的一个标准的 python 接口方法，最终调用了 **PyThread_start_new_thread** 方法，而这个方法，在 `Python/thread_pthread.h` 中实现：  
```c
unsigned long
PyThread_start_new_thread(void (*func)(void *), void *arg)
{
    pthread_t th;
    int status;
#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED)
    pthread_attr_t attrs;
#endif
#if defined(THREAD_STACK_SIZE)
    size_t      tss;
#endif

    dprintf((&quot;PyThread_start_new_thread called\n&quot;));
    if (!initialized)
        PyThread_init_thread();

#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED)
    if (pthread_attr_init(&amp;attrs) != 0)
        return PYTHREAD_INVALID_THREAD_ID;
#endif
#if defined(THREAD_STACK_SIZE)
    PyThreadState *tstate = _PyThreadState_GET();
    size_t stacksize = tstate ? tstate-&gt;interp-&gt;pythread_stacksize : 0;
    tss = (stacksize != 0) ? stacksize : THREAD_STACK_SIZE;
    if (tss != 0) {
        if (pthread_attr_setstacksize(&amp;attrs, tss) != 0) {
            pthread_attr_destroy(&amp;attrs);
            return PYTHREAD_INVALID_THREAD_ID;
        }
    }
#endif
#if defined(PTHREAD_SYSTEM_SCHED_SUPPORTED)
    pthread_attr_setscope(&amp;attrs, PTHREAD_SCOPE_SYSTEM);
#endif

    pythread_callback *callback = PyMem_RawMalloc(sizeof(pythread_callback));

    if (callback == NULL) {
      return PYTHREAD_INVALID_THREAD_ID;
    }

    callback-&gt;func = func;
    callback-&gt;arg = arg;

    status = pthread_create(&amp;th,
#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED)
                             &amp;attrs,
#else
                             (pthread_attr_t*)NULL,
#endif
                             pythread_wrapper, callback);

#if defined(THREAD_STACK_SIZE) || defined(PTHREAD_SYSTEM_SCHED_SUPPORTED)
    pthread_attr_destroy(&amp;attrs);
#endif

    if (status != 0) {
        PyMem_RawFree(callback);
        return PYTHREAD_INVALID_THREAD_ID;
    }

    pthread_detach(th);

#if SIZEOF_PTHREAD_T &lt;= SIZEOF_LONG
    return (unsigned long) th;
#else
    return (unsigned long) *(unsigned long *) &amp;th;
#endif
}
```
&amp;emsp;&amp;emsp;由此可知，python 的线程创建最终也落到 **pthread_create** 方法上，那么如果要关闭这个线程，是不是就直接使用 **pthread_kill** 就可以了？</content><author><name></name></author><summary type="html">  这个想法起初只是为了找到 python 3 下的 threading.Thread 中类似于线程关闭的方法，可惜似乎没有直接的实现。在 python 2 下 Thread 实例的退出可以调用 Thread._Thread__stop() 方法来完成，但是这个内置方法在 python 3 下已经没有，通过代码跟踪发现 threading.py 并不是实现 python 线程的基础文件，真正的启动操作应该是调用 cpython 暴露出来的 start_new_thread 方法来完成启动，在启动的同时传入了 self._bootstrap() 做一些初始化操作： ```python def start(self): “&quot;”Start the thread’s activity.</summary></entry><entry><title type="html">构建 VS Code Extension 的实践总结</title><link href="https://fuzhibo.site/vscode/2019/12/12/how-to-build-vscode-extension.html" rel="alternate" type="text/html" title="构建 VS Code Extension 的实践总结" /><published>2019-12-12T14:19:29+08:00</published><updated>2019-12-12T14:19:29+08:00</updated><id>https://fuzhibo.site/vscode/2019/12/12/how-to-build-vscode-extension</id><content type="html" xml:base="https://fuzhibo.site/vscode/2019/12/12/how-to-build-vscode-extension.html">&amp;emsp;&amp;emsp;最近突然想写一个 vs code 插件用来链接 gitlab 方便做一些管理，于是就有了这样一个折腾的笔记。  
&amp;emsp;  
&amp;emsp;&amp;emsp;首先是参考 [Your First Extension](https://code.visualstudio.com/api/get-started/your-first-extension) 这篇文章来一步步的构建自己的插件。但是在启动 debug 的时候遇到了问题，程序会一直卡在 `Building` 的状态。  
&amp;emsp;  
&amp;emsp;&amp;emsp;因为插件本身还是以 npm 作为基础，所以还是得从 package.json 入手调查。最后发现有这么 `scripts` 属性下有这么一个配置：`&quot;watch&quot;: &quot;tsc -watch -p ./&quot;`，看起来这里应该就是阻塞点了。本来应该是提供来 npm 自身来进行输入文件的监控，但是 vs code 阻塞在了这里。由于不知道为什么会添加一个 watch 在这里也不明白为什么 vs code debug 的时候会阻塞。现在的解决办法就只有删掉它。删掉之后，一切就可以按照预期执行了。看来原因在于执行 prepublish 的时候出现的问题。  
&amp;emsp;  
&amp;emsp;&amp;emsp;打通了插件的构建流程后，那么就可以正是开始插件的开发了，这里再记录一个 vs code 官方的插件教程[仓库](https://github.com/microsoft/vscode-extension-samples)，可以作为自己开发的参考。</content><author><name></name></author><summary type="html">  最近突然想写一个 vs code 插件用来链接 gitlab 方便做一些管理，于是就有了这样一个折腾的笔记。     首先是参考 Your First Extension 这篇文章来一步步的构建自己的插件。但是在启动 debug 的时候遇到了问题，程序会一直卡在 Building 的状态。     因为插件本身还是以 npm 作为基础，所以还是得从 package.json 入手调查。最后发现有这么 scripts 属性下有这么一个配置：&quot;watch&quot;: &quot;tsc -watch -p ./&quot;，看起来这里应该就是阻塞点了。本来应该是提供来 npm 自身来进行输入文件的监控，但是 vs code 阻塞在了这里。由于不知道为什么会添加一个 watch 在这里也不明白为什么 vs code debug 的时候会阻塞。现在的解决办法就只有删掉它。删掉之后，一切就可以按照预期执行了。看来原因在于执行 prepublish 的时候出现的问题。     打通了插件的构建流程后，那么就可以正是开始插件的开发了，这里再记录一个 vs code 官方的插件教程仓库，可以作为自己开发的参考。</summary></entry><entry><title type="html">理解 Jekyll 项目下的 Gemfile</title><link href="https://fuzhibo.site/jekyll,frontend/2019/12/12/understad-jekyll-gemfle.html" rel="alternate" type="text/html" title="理解 Jekyll 项目下的 Gemfile" /><published>2019-12-12T10:07:29+08:00</published><updated>2019-12-12T10:07:29+08:00</updated><id>https://fuzhibo.site/jekyll,frontend/2019/12/12/understad-jekyll-gemfle</id><content type="html" xml:base="https://fuzhibo.site/jekyll,frontend/2019/12/12/understad-jekyll-gemfle.html">&amp;emsp;&amp;emsp;Jekyll 框架是通过 bundler 安装的，那么这个安装过程的控制就是通过 Gemfile 来完成的，在这个过程中 bundler 做了什么呢？  
&amp;emsp;  
&amp;emsp;&amp;emsp;首先，指定了源 `source`：
```yaml
source &quot;https://rubygems.org&quot;
```
&amp;emsp;  
&amp;emsp;&amp;emsp;接下来，文件设置了 `Gems`：
```yaml
# 这里指定了包 jekyll 并且指定了版本最好是 4.0.0 或者之后的安全版本
# Happy Jekylling!
gem &quot;jekyll&quot;, &quot;~&gt; 4.0.0&quot;
# This is the default theme for new Jekyll sites. You may change this to anything you like.
gem &quot;minima&quot;, &quot;~&gt; 2.5&quot;
```
&amp;emsp;&amp;emsp;版本运算符一览
&gt;* = Equal To &quot;=1.0&quot;
&gt;* != Not Equal To &quot;!=1.0&quot;
&gt;* &amp;gt; Greater Than &quot;&gt;1.0&quot;
&gt;* &lt; Less Than &quot;&lt;1.0&quot;
&gt;* &amp;gt;= Greater Than or Equal To &quot;&gt;=1.0&quot;
&gt;* &lt;= Less Than or Equal To &quot;&lt;=1.0&quot;
&gt;* ~&gt; Pessimistically Greater Than or Equal To &quot;~&gt;1.0&quot;

&amp;emsp;&amp;emsp;理解 `~&gt;` 操作符，它等价于一个范围的取值操作。
&gt;* gem &quot;my_gem&quot;, &quot;~&gt; 1.0&quot; –&gt; gem &quot;my_gem&quot;, &quot;&gt;= 1.0&quot;, &quot;&lt; 2.0&quot;
&gt;* gem &quot;my_gem&quot;, &quot;~&gt; 1.5.0&quot; –&gt; gem &quot;my_gem&quot;, &quot;&gt;= 1.5.0&quot;, &quot;&lt; 1.6.0&quot;
&gt;* gem &quot;my_gem&quot;, &quot;~&gt; 1.5.5&quot; –&gt; gem &quot;my_gem&quot;, &quot;&gt;= 1.5.5&quot;, &quot;&lt; 1.6.0&quot;

&amp;emsp;&amp;emsp;一个 gem 可以属于一个或者多个 group，当它不属于任何 group 的时候，它被放入了 `:default group`。这里创建了一个专门的 group `jekyll_plugins`。
```yaml
# If you want to use GitHub Pages, remove the &quot;gem &quot;jekyll&quot;&quot; above and
# uncomment the line below. To upgrade, run `bundle update github-pages`.
# gem &quot;github-pages&quot;, group: :jekyll_plugins
# If you have any plugins, put them here!
group :jekyll_plugins do
  gem &quot;jekyll-feed&quot;, &quot;~&gt; 0.12&quot;
end
```
&amp;emsp;&amp;emsp;如果是 `Windows` 和 `JRuby`的平台安装 Jekyll 则还需要安装 tzinfo-data。因为自己是 Ubuntu 作为开发平台，所以就不深入展开了。
```yaml
# Windows and JRuby does not include zoneinfo files, so bundle the tzinfo-data gem
# and associated library.
install_if -&gt; { RUBY_PLATFORM =~ %r!mingw|mswin|java! } do
  gem &quot;tzinfo&quot;, &quot;~&gt; 1.2&quot;
  gem &quot;tzinfo-data&quot;
end
```
&amp;emsp;&amp;emsp;安装 `wdm` 依赖的时候需要注意平台，这个可以通过 `Gem.win_platform` 来进行判断。
```yaml
# Performance-booster for watching directories on Windows
gem &quot;wdm&quot;, &quot;~&gt; 0.1.1&quot;, :install_if =&gt; Gem.win_platform?
```
&amp;emsp;&amp;emsp;更多详细有关 `Gemfile` 的内容，可以参考这些[文章](https://ruby-china.org/topics/26655)。至于 `Gemfile.lock` 这个文件是使用 `bundle install` 的时候自动生成的文件，具体可以参考这个[文章](https://bundler.io/v1.7/rationale.html)。</content><author><name></name></author><summary type="html">  Jekyll 框架是通过 bundler 安装的，那么这个安装过程的控制就是通过 Gemfile 来完成的，在这个过程中 bundler 做了什么呢？     首先，指定了源 source： source &quot;https://rubygems.org&quot;     接下来，文件设置了 Gems： # 这里指定了包 jekyll 并且指定了版本最好是 4.0.0 或者之后的安全版本 # Happy Jekylling! gem &quot;jekyll&quot;, &quot;~&amp;gt; 4.0.0&quot; # This is the default theme for new Jekyll sites. You may change this to anything you like. gem &quot;minima&quot;, &quot;~&amp;gt; 2.5&quot;   版本运算符一览 = Equal To “=1.0” != Not Equal To “!=1.0” &amp;gt; Greater Than “&amp;gt;1.0” &amp;lt; Less Than “&amp;lt;1.0” &amp;gt;= Greater Than or Equal To “&amp;gt;=1.0” &amp;lt;= Less Than or Equal To “&amp;lt;=1.0” ~&amp;gt; Pessimistically Greater Than or Equal To “~&amp;gt;1.0”</summary></entry><entry><title type="html">使用 jekyll 构建 github pages 的学习笔记整理</title><link href="https://fuzhibo.site/jekyll,frontend/2019/12/11/jekyll-blog-study-trajectory.html" rel="alternate" type="text/html" title="使用 jekyll 构建 github pages 的学习笔记整理" /><published>2019-12-11T16:19:29+08:00</published><updated>2019-12-11T16:19:29+08:00</updated><id>https://fuzhibo.site/jekyll,frontend/2019/12/11/jekyll-blog-study-trajectory</id><content type="html" xml:base="https://fuzhibo.site/jekyll,frontend/2019/12/11/jekyll-blog-study-trajectory.html">&amp;emsp;&amp;emsp;这里只是将自己使用 Jekyll 构建 github pages 的过程整理一下。  

&amp;emsp;&amp;emsp;首先，当然是在 github 上创建一个自己的账号，然后新建一个 `&lt;username&gt;.github.io` 的仓库，这样 github 就可以把这个仓库识别为 **github pages**，不过就实际来说建立一个其它名字的仓库也是可以设置 **github pages** 的，区别在于其它名字的仓库允许使用 `master 分支下的 docs 目录`作为 **github pages** 访问页面的存放目录，也可以使用其它分支作为访问页面的存放目录。如果只是用户的 **github pages** 那么就只会允许在 `master`分支下创建相关的页面。这个对我初期的搭建造成了极大的困扰，一开始我一直以为只要是 **github pages** 就可以选择其它的目录，直到发现以 `&lt;username&gt;.github.io` 命名的仓库下的相关设置页面下并没有下拉框可以供分支或者 `master/docs` 选择。  

&amp;emsp;&amp;emsp;建立好仓库后，只需要一个 index.html 就可以看到效果了。现在可以使用 `https://&lt;username&gt;.github.io` (同时要在仓库设置选项卡下勾选 `Enforce HTTPS`) 来进行访问。如果想要使用自己的域名，那么就要去购买一个域名然后在相关的域名提供商页面下配置该域名的 A 记录和 CNAME 。同时要在仓库的根目录下新建一个 CNAME 的文件，里面就只填写自己想要使用的域名。
### DNS 的配置：
```console
@          A             185.199.108.153
@          A             185.199.109.153
@          A             185.199.110.153
@          A             185.199.111.153
www      CNAME           username.github.io.
```
### CNAME 文件的配置
```console
custom.domain
```
&amp;emsp;  
&amp;emsp;&amp;emsp;更改好配置后，现在可以通过自己自定义的域名来访问页面了。接下来需要思考一下怎么样来搭建自己的博客，github 推荐是用 Jekyll，这是一个专门的将纯文本转换为静态博客网站的的框架，使用 `Ruby` 开发。那么现在就需要去学习如何安装并使用这套框架。  
1. 安装 Ruby（在 ubuntu 上进行安装）
&gt;&amp;emsp;&amp;emsp;使用这个命令进行安装：`sudo apt install ruby-full`；检测 Ruby ：`ruby --version`。安装好 Ruby 之后其自带一个 `gem` 的工具来管理 Ruby 库和程序。默认是通过 `Ruby Gem`（例如 [rubygems.org](http://rubygems.org/)）源来进行查找、安装、升级和卸载软件包。但是国内访问速度很慢，还是要换源。换源方法可以参考 [gems.ruby-china.com](https://gems.ruby-china.com/) 上的教程来完成源的替换。
2. 安装 Bundler
&gt;&amp;emsp;&amp;emsp;这个是能够跟踪并安装所需的特定版本的 gem，以此来为 Ruby 项目提供一致运行环境的工具（给人感觉类似 node 的 npm 工具）。Jekyll 不可避免会使用这个工具，所以需要安装配置它。使用这个命令来安装：`gem install bundler`。装好后在使用的过程中可能会遇到 `'Cant find gem bundler (&gt;= 0.a) with executable bundle'` 这样的异常，解决办法是运行 `gem update --system` 来升级 gem，这其实是 gem 的特定版本的 bug 升级后就可以解决。
3. 安装 Jekyll
&gt;&amp;emsp;&amp;emsp;这个命令很简单：`sudo gem install jekyll`。安装完成后，使用 `jekyll new myjekyllblog` 就可以初始化一个 github pages 的项目，在这个过程中，jekyll 会调用 bundle install 来完成框架环境的搭建。
4. 使用 Jekyll
&gt;&amp;emsp;&amp;emsp;使用命令 `jekyll serve --watch` 就可以启动一个调试后台来进行页面的查看（访问 http://127.0.0.1:4000）即可。  
&gt;&amp;emsp;  
&gt; &amp;emsp;&amp;emsp;关于这个初始页面的简易配置可以通过 _config.yml 来完成。
```yaml
title: My Jekyll Blog
email: example@example.com
description: My latest stories and photos
url: https://myjekyllblog.github.io
twitter_username: myjekyllblog
github_username: myjekyllblog
```
&gt;&amp;emsp;&amp;emsp;如果要添加自己的博客文章，都在 `_post` 这个目录下面。</content><author><name></name></author><summary type="html">  这里只是将自己使用 Jekyll 构建 github pages 的过程整理一下。</summary></entry><entry><title type="html">Welcome to My Blog!</title><link href="https://fuzhibo.site/my/life/2019/12/06/welcome-to-my-blog.html" rel="alternate" type="text/html" title="Welcome to My Blog!" /><published>2019-12-06T16:28:29+08:00</published><updated>2019-12-06T16:28:29+08:00</updated><id>https://fuzhibo.site/my/life/2019/12/06/welcome-to-my-blog</id><content type="html" xml:base="https://fuzhibo.site/my/life/2019/12/06/welcome-to-my-blog.html">This is my first time to build a github pages, it seems like an interesting process. I use [Jekyll](http://jekyllcn.com/) to build my own site, and applied for a domain name for my site. I learned how to build a public web site during the prcess. Maybe it can be used to solve more use cases, like a static web shop or any other web site which do not need much interactivity.

I build this blog to record my study notes, now the world is growing faster and faster, I want to keep learning to keep up with this rhythm. At begging, I only write C Language in embedded system. However I found it's not enough soon, C isn't everything, some issue will be complex if I only use C. So, I try to learn other Langrages, like C++, shell, python, perl, golang and so on. My work range also from embedded system to any other industry, like backend server development and frontend page. Now I think a programmer should not be familiar with only one technology. We need to learn more to adapt to this complex and changing era. My mother Language is Chinese, now I'm working hard to learn english as my second mother language. Capital without borders, our work also have no borders. I like a word says by K.S. Li :`此心安处是吾乡`(&quot;This place of mind is my hometown&quot;).</content><author><name></name></author><summary type="html">This is my first time to build a github pages, it seems like an interesting process. I use Jekyll to build my own site, and applied for a domain name for my site. I learned how to build a public web site during the prcess. Maybe it can be used to solve more use cases, like a static web shop or any other web site which do not need much interactivity.</summary></entry></feed>